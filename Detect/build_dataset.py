# import the necessary packages
from System.iou import compute_iou
from System import config
# from bs4 import BeautifulSoup
from imutils import paths
import cv2
import os
import pandas as pd
# loop over the output positive and negative directories
for dirPath in (config.POSITVE_PATH, config.NEGATIVE_PATH):
	# if the output directory does not exist yet, create it
	if not os.path.exists(dirPath):
		os.makedirs(dirPath)
# grab all image paths in the input images directory
imagePaths = list(paths.list_images(config.ORIG_IMAGES))
# initialize the total number of positive and negative images we have
# saved to disk so far
totalPositive = 0
totalNegative = 0
# loop over the image paths
annotationsOri = pd.read_csv('annotations.csv')
annotations = annotationsOri.sample(100)
print("BEGIN____")
print(annotations)
print(annotations)
input("STOP")
import numpy as np
for (i, imagePath) in enumerate(np.asarray(annotations.file_name)):
	annoItem = annotations.query("file_name == '{}'".format(imagePath)).iloc[0]
	# show a progress report
	print("[INFO] processing image {}/{}...".format(i + 1,len(np.asarray(annotations.file_name))))
	# extract the filename from the file path and use it to derive
	# the path to the XML annotation file

	filename = 'tfsigns/images/' + imagePath.split(os.path.sep)[-1]
	print(filename)
	# filename = filename[:filename.rfind(".")]
	# print(filename)

	gtBoxes = []
    # extract the image dimensions
	w = int(annoItem['width'])
	h = int(annoItem['height'])
	# loop over all 'object'elements
	# extract the label and bounding box coordinates
	label = 'traffic_sign'
	xMin = int(annoItem['x1'])
	yMin = int(annoItem['y1'])
	xMax = int(annoItem['x2'])
	yMax = int(annoItem['y2'])
	# truncate any bounding box coordinates that may fall
	# outside the boundaries of the image
	xMin = max(0, xMin)
	yMin = max(0, yMin)
	xMax = min(w, xMax)
	yMax = min(h, yMax)
	# update our list of ground-truth bounding boxes
	gtBoxes.append((xMin, yMin, xMax, yMax))
	image = cv2.imread(filename)

	# run selective search on the image and initialize our list of
	# proposed boxes
	ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()
	ss.setBaseImage(image)
	ss.switchToSelectiveSearchFast()
	rects = ss.process()
	proposedRects = []
	# loop over the rectangles generated by selective search
	for (x, y, w, h) in rects:
		# convert our bounding boxes from (x, y, w, h) to (startX,
		# startY, startX, endY)
		proposedRects.append((x, y, x + w, y + h))
	# initialize counters used to count the number of positive and
	# negative ROIs saved thus far
	positiveROIs = 0
	negativeROIs = 0
	# loop over the maximum number of region proposals
	for proposedRect in proposedRects[:config.MAX_PROPOSALS]:
		# unpack the proposed rectangle bounding box
		(propStartX, propStartY, propEndX, propEndY) = proposedRect
		# loop over the ground-truth bounding boxes
		for gtBox in gtBoxes:
			# compute the intersection over union between the two
			# boxes and unpack the ground-truth bounding box
			iou = compute_iou(gtBox, proposedRect)
			(gtStartX, gtStartY, gtEndX, gtEndY) = gtBox
			# initialize the ROI and output path
			roi = None
			outputPath = None
			# check to see if the IOU is greater than 70% *and* that
			# we have not hit our positive count limit
		
			if iou > 0.7 and positiveROIs <= config.MAX_POSITIVE:
				# extract the ROI and then derive the output path to
				# the positive instance
				roi = image[propStartY:propEndY, propStartX:propEndX]
				filename = "{}.png".format(totalPositive)
				outputPath = os.path.sep.join([config.POSITVE_PATH,filename])
				# increment the positive counters
				positiveROIs += 1
				totalPositive += 1
            # determine if the proposed bounding box falls *within*
			# the ground-truth bounding box
			fullOverlap = propStartX >= gtStartX
			fullOverlap = fullOverlap and propStartY >= gtStartY
			fullOverlap = fullOverlap and propEndX <= gtEndX
			fullOverlap = fullOverlap and propEndY <= gtEndY
            # check to see if there is not full overlap *and* the IoU
			# is less than 5% *and* we have not hit our negative
			# count limit
			if not fullOverlap and iou < 0.05 and \
				negativeROIs <= config.MAX_NEGATIVE:
				# extract the ROI and then derive the output path to
				# the negative instance
				roi = image[propStartY:propEndY, propStartX:propEndX]
				filename = "{}.png".format(totalNegative)
				outputPath = os.path.sep.join([config.NEGATIVE_PATH,
					filename])
				# increment the negative counters
				negativeROIs += 1
				totalNegative += 1
            # check to see if both the ROI and output path are valid
			if roi is not None and outputPath is not None:
				# resize the ROI to the input dimensions of the CNN
				# that we'll be fine-tuning, then write the ROI to
				# disk
				roi = cv2.resize(roi, config.INPUT_DIMS,
					interpolation=cv2.INTER_CUBIC)
				cv2.imwrite(outputPath, roi)